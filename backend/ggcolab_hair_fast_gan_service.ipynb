{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVUfilO_c6wY",
        "outputId": "c79f5782-5a21-4095-f03e-61e3da37b726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HairFastGAN'...\n",
            "remote: Enumerating objects: 565, done.\u001b[K\n",
            "remote: Counting objects: 100% (565/565), done.\u001b[K\n",
            "remote: Compressing objects: 100% (430/430), done.\u001b[K\n",
            "remote: Total 565 (delta 88), reused 558 (delta 83), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (565/565), 3.79 MiB | 12.80 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "/content/HairFastGAN\n"
          ]
        }
      ],
      "source": [
        "# Clone git repo\n",
        "!git clone https://github.com/AIRI-Institute/HairFastGAN\n",
        "%cd HairFastGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwwNggYSdFCG",
        "outputId": "987718c7-b510-4a98-9747-a7dc4b04899c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-08 00:58:27--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250108T005827Z&X-Amz-Expires=300&X-Amz-Signature=8ff47a7b25f8aebb837ca778f28c2cf9240658fc1d5e80bb9cdff7db83383e81&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-01-08 00:58:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250108T005827Z&X-Amz-Expires=300&X-Amz-Signature=8ff47a7b25f8aebb837ca778f28c2cf9240658fc1d5e80bb9cdff7db83383e81&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-01-08 00:58:27 (4.28 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ],
      "source": [
        "# Install ninja - small build system to run C++, C\n",
        "# Install Ninja - small build system https://github.com/ninja-build/ninja\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vHDtr4WdII2",
        "outputId": "57f98dc5-bbca-4610-dbb5-c5e555725058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fpie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install lib\n",
        "# pillow==10.0.0 => error\n",
        "!pip install pyngrok streamlit pillow==11.0.0 face_alignment dill==0.2.7.1 addict fpie git+https://github.com/openai/CLIP.git -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k-D3O9kdI5d",
        "outputId": "d1e68d4f-fb2c-44d9-d44b-fcf4c95e627a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mUHj6w5dK6k",
        "outputId": "f65f633e-dabb-4438-b5b9-4d9befa53e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HairFastGAN'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 67 (delta 4), reused 0 (delta 0), pack-reused 1 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (67/67), 7.75 MiB | 6.31 MiB/s, done.\n",
            "Filtering content: 100% (34/34), 7.20 GiB | 59.21 MiB/s, done.\n",
            "Encountered 1 file(s) that should have been pointers, but weren't:\n",
            "\tdocs/assets/logo.webp\n"
          ]
        }
      ],
      "source": [
        "# Download pretrain\n",
        "!git clone https://huggingface.co/AIRI-Institute/HairFastGAN\n",
        "!cd HairFastGAN && git lfs pull && cd ..\n",
        "!mv HairFastGAN/pretrained_models pretrained_models\n",
        "!mv HairFastGAN/input input\n",
        "!rm -rf HairFastGAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow==9.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "eqlAa0MfsSZO",
        "outputId": "c6c27b54-5914-418e-bd2e-adc3c35253f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow==9.0.0\n",
            "  Downloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Downloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.1.0\n",
            "    Uninstalling Pillow-9.1.0:\n",
            "      Successfully uninstalled Pillow-9.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.24.0 requires pillow>=9.1, but you have pillow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pillow-9.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "e2646cabccaa4573823e1240c635dc53"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HpCFOMGnML3",
        "outputId": "e7ecb0fd-9680-4581-e735-1b3739965e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pillow\n",
            "Version: 11.0.0\n",
            "Summary: Python Imaging Library (Fork)\n",
            "Home-page: https://python-pillow.org\n",
            "Author: \n",
            "Author-email: \"Jeffrey A. Clark\" <aclark@aclark.net>\n",
            "License: MIT-CMU\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: bokeh, diffusers, dopamine_rl, fastai, imageio, imgaug, matplotlib, scikit-image, sentence-transformers, streamlit, torchvision, wordcloud\n"
          ]
        }
      ],
      "source": [
        "!pip show Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfmjGwVgdoC7",
        "outputId": "b3d0c596-d011-4e75-8964-a4cd8dcbf584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Khai báo các thư viện\n",
        "from pathlib import Path\n",
        "from hair_swap import HairFast, get_parser\n",
        "import torchvision.transforms as T\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NliuevgbdtO0",
        "outputId": "d5b45e74-5b6c-42b7-a9f0-eb2b2454883b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading StyleGAN2 from checkpoint: pretrained_models/StyleGAN/ffhq.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/HairFastGAN/models/Net.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(self.opts.ckpt)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 85.2MB/s]\n",
            "/content/HairFastGAN/models/CtrlHair/external_code/face_parsing/my_parsing_util.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  FaceParsing.bise_net.load_state_dict(torch.load(save_pth))\n",
            "/content/HairFastGAN/models/FeatureStyleEncoder/nets/feature_style_encoder.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet50.load_state_dict(torch.load(opts.arcface_model_path))\n",
            "/content/HairFastGAN/models/FeatureStyleEncoder/trainer.py:190: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  stylegan_state_dict = torch.load(stylegan_model_path, map_location='cpu')\n",
            "/content/HairFastGAN/models/FeatureStyleEncoder/trainer.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.Arcface.load_state_dict(torch.load(self.opts.arcface_model_path))\n",
            "/content/HairFastGAN/models/FeatureStyleEncoder/trainer.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.parsing_net.load_state_dict(torch.load(self.opts.parsing_model_path))\n",
            "/content/HairFastGAN/models/FeatureStyleEncoder/FSencoder.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  trainer.enc.load_state_dict(torch.load(opts.pretrained_model_path))\n",
            "/content/HairFastGAN/models/encoder4editing/utils/model_utils.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(checkpoint_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading e4e over the pSp framework from checkpoint: pretrained_models/encoder4editing/e4e_ffhq_encode.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/HairFastGAN/models/encoder4editing/models/psp.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(self.opts.checkpoint_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network [SPADEGenerator] was created. Total number of parameters: 266.9 million. To see the architecture, do print(network).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/HairFastGAN/models/sean_codes/util/util.py:208: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  weights = torch.load(save_path)\n",
            "/content/HairFastGAN/models/Alignment.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.mask_generator.load_state_dict(torch.load('pretrained_models/ShapeAdaptor/mask_generator.pth'))\n",
            "/content/HairFastGAN/models/Alignment.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.rotate_model.load_state_dict(torch.load(self.opts.rotate_checkpoint)['model_state_dict'])\n",
            "/content/HairFastGAN/models/Blending.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  blending_checkpoint = torch.load(self.opts.blending_checkpoint)\n",
            "100%|███████████████████████████████████████| 335M/335M [00:04<00:00, 82.0MiB/s]\n",
            "/content/HairFastGAN/models/Net.py:341: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  resnet50.load_state_dict(torch.load(opts.arcface_model_path))\n",
            "/content/HairFastGAN/models/Encoders.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.latent_avg = torch.load('pretrained_models/PostProcess/latent_avg.pt', map_location=torch.device('cuda'))\n",
            "/content/HairFastGAN/models/Blending.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.post_process.load_state_dict(torch.load(self.opts.pp_checkpoint)['model_state_dict'])\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo model để test\n",
        "model_args = get_parser()\n",
        "hair_fast = HairFast(model_args.parse_args([]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-W8E6CnNgCbn",
        "outputId": "742ae26b-2c2d-4244-e5f7-5addc888d9c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://m8p1cqawm4b-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ]
        }
      ],
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8xOVPVoqWSw",
        "outputId": "1f799b12-233c-4bb9-bdc8-d69cc5b6a056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask-cors) (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-cors) (3.0.2)\n",
            "Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffKPCDRbsJ5m",
        "outputId": "d64539a8-58a2-467c-e4ac-91eba19697e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2fwwGWWU63oiIg8vpe3aRAYGdOE_66pnGXBJvendohT1LwqLg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYQQGi48sOwz"
      },
      "outputs": [],
      "source": [
        "!pkill ngrok\n",
        "# !ngrok http 5000&>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyv11gbR5Wx_",
        "outputId": "7321f0a0-8192-4412-aa19-9c5aa781ae4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok Tunnel URL: https://5433-35-197-116-80.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Khởi động ngrok tunnel\n",
        "http_tunnel = ngrok.connect(5000)\n",
        "print(\"Ngrok Tunnel URL:\", http_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIP8Jc26qyrW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFm1Llw5dt6j",
        "outputId": "8d8a7f91-1d87-4ef5-9cc4-cdc8c084fab6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FileStorage: 'Messenger_creation_E541F771-F9A1-4AC5-AF58-E9B97415FA0E.jpeg' ('image/*')>\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/HairFastGAN/models/sean_codes/models/pix2pix_model.py:140: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  input_label = self.FloatTensor(bs, nc, h, w).zero_()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py:115: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n",
            "<class 'torch.Tensor'>\n",
            "(1024, 1024)\n",
            "RGB\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/Jan/2025 01:08:06] \"POST /swap-hair HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FileStorage: 'Messenger_creation_E541F771-F9A1-4AC5-AF58-E9B97415FA0E.jpeg' ('image/*')>\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "7\n",
            "<class 'torch.Tensor'>\n",
            "(1024, 1024)\n",
            "RGB\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/Jan/2025 01:08:34] \"POST /swap-hair HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FileStorage: 'Messenger_creation_E541F771-F9A1-4AC5-AF58-E9B97415FA0E.jpeg' ('image/*')>\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "7\n",
            "<class 'torch.Tensor'>\n",
            "(1024, 1024)\n",
            "RGB\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/Jan/2025 01:13:22] \"POST /swap-hair HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FileStorage: 'Messenger_creation_E541F771-F9A1-4AC5-AF58-E9B97415FA0E.jpeg' ('image/*')>\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "7\n",
            "<class 'torch.Tensor'>\n",
            "(1024, 1024)\n",
            "RGB\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/Jan/2025 01:25:14] \"POST /swap-hair HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FileStorage: 'Messenger_creation_E541F771-F9A1-4AC5-AF58-E9B97415FA0E.jpeg' ('image/*')>\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "7\n",
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/Jan/2025 01:40:23] \"POST /swap-hair HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024, 1024)\n",
            "RGB\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "<FileStorage: 'Messenger_creation_E541F771-F9A1-4AC5-AF58-E9B97415FA0E.jpeg' ('image/*')>\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "Number of faces detected: 1\n",
            "7\n",
            "<class 'torch.Tensor'>\n",
            "(1024, 1024)\n",
            "RGB\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [08/Jan/2025 02:15:19] \"POST /swap-hair HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify, send_file\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import uuid\n",
        "import os\n",
        "import traceback\n",
        "import gc\n",
        "# from pathlib import Path\n",
        "from flask_cors import CORS\n",
        "\n",
        "app = Flask(__name__)\n",
        "# run_with_ngrok(app)\n",
        "CORS(app)\n",
        "\n",
        "# Hàm tải ảnh từ URL\n",
        "def load_bytes_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    return BytesIO(response.content)\n",
        "\n",
        "def save_bytesio_to_file(bytes_io, prefix):\n",
        "    if not os.path.exists('/content/uploads'):\n",
        "        os.mkdir('/content/uploads')\n",
        "    unique_filename = f\"{prefix}_{uuid.uuid4()}.jpg\"\n",
        "    file_path = os.path.join('/content/uploads', unique_filename)\n",
        "    with open(file_path, 'wb') as f:\n",
        "        f.write(bytes_io.getbuffer())\n",
        "    return file_path\n",
        "\n",
        "# Hàm xóa tệp ảnh\n",
        "def delete_file(file_path):\n",
        "    if file_path is not None and os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "\n",
        "def resize_with_aspect_ratio(image, base_width):\n",
        "    w_percent = (base_width / float(image.size[0]))\n",
        "    h_size = int((float(image.size[1]) * float(w_percent)))\n",
        "    return image.resize((base_width, h_size), Image.Resampling.LANCZOS)\n",
        "\n",
        "\n",
        "\n",
        "# Hàm để giải phóng GPU sau khi hoàn thành request\n",
        "@app.after_request\n",
        "def cleanup_gpu(response):\n",
        "    try:\n",
        "        # Giải phóng GPU\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during GPU cleanup: {e}\")\n",
        "    return response\n",
        "\n",
        "\n",
        "# API nhận ảnh và thực hiện hoán đổi tóc\n",
        "@app.route('/swap-hair', methods=['POST'])\n",
        "def swap_hair():\n",
        "    face_path = None\n",
        "    shape_path = None\n",
        "    color_path = None\n",
        "#     save_path = None\n",
        "    try:\n",
        "        # Lấy tham số face_path (là ảnh tải lên từ người dùng)\n",
        "        face_file = request.files['image']\n",
        "        print(face_file)\n",
        "        face_bytes = BytesIO(face_file.read())\n",
        "        print(2)\n",
        "\n",
        "        # Lấy shape_path và color_path (là các URL tới hình ảnh)\n",
        "        shape_url = request.form['hairStyleUrl']\n",
        "        print(3)\n",
        "        color_url = request.form['hairColorUrl']\n",
        "        print(4)\n",
        "\n",
        "        # Tải ảnh shape và color từ URL\n",
        "        shape_bytes = load_bytes_from_url(shape_url)\n",
        "        print(5)\n",
        "        color_bytes = load_bytes_from_url(color_url)\n",
        "        print(6)\n",
        "\n",
        "        # Lưu các tệp ảnh với UUID v4\n",
        "        face_path = save_bytesio_to_file(face_bytes, 'face')\n",
        "        shape_path = save_bytesio_to_file(shape_bytes, 'shape')\n",
        "        color_path = save_bytesio_to_file(color_bytes, 'color')\n",
        "\n",
        "        # Chuyển đổi ảnh sang định dạng tensor phù hợp nếu cần\n",
        "        # (có thể cần chuyển đổi tuỳ thuộc vào cách HairFast sử dụng dữ liệu ảnh)\n",
        "\n",
        "        # Chạy hàm swap\n",
        "        final_image, face_align, shape_align, color_align = hair_fast.swap(face_path, shape_path, color_path, align=True)\n",
        "        print(7)\n",
        "        print(type(final_image))\n",
        "        final_image = T.functional.to_pil_image(final_image)\n",
        "        print(final_image.size)\n",
        "        print(final_image.mode)\n",
        "        if final_image.mode != \"RGB\":\n",
        "            final_image = final_image.convert(\"RGB\")\n",
        "        print(8)\n",
        "\n",
        "#         save_path = Path('/kaggle/working/uploads', f'result_{uuid.uuid4()}.jpg')\n",
        "#         print(type(final_image))\n",
        "#         print(save_path, final_image)\n",
        "#         final_image.save(save_path)\n",
        "\n",
        "        # Chuyển đổi ảnh kết quả thành định dạng có thể trả về\n",
        "#         final_image_pil = Image.fromarray(final_image)  # Chuyển tensor thành PIL image\n",
        "\n",
        "        new_base_width = 400\n",
        "        final_image = resize_with_aspect_ratio(final_image, new_base_width)\n",
        "        print(9)\n",
        "        img_io = BytesIO()\n",
        "        print(10)\n",
        "        final_image.save(img_io, format='PNG')\n",
        "        print(11)\n",
        "        img_io.seek(0)\n",
        "        print(12)\n",
        "\n",
        "        del final_image, face_align, shape_align, color_align\n",
        "        torch.cuda.empty_cache()  # Giải phóng bộ nhớ GPU ngay lập tức sau khi hoàn thành\n",
        "\n",
        "        # Xóa các tệp ảnh sau khi trả về response\n",
        "        delete_file(face_path)\n",
        "        delete_file(shape_path)\n",
        "        delete_file(color_path)\n",
        "#         delete_file(save_path)\n",
        "\n",
        "        print(13)\n",
        "\n",
        "        # Trả về ảnh kết quả\n",
        "\n",
        "        return send_file(img_io, mimetype='image/png')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(traceback.format_exc())\n",
        "        delete_file(face_path)\n",
        "        delete_file(shape_path)\n",
        "        delete_file(color_path)\n",
        "#         delete_file(save_path)\n",
        "        return jsonify({'error': str(e)}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK_-d8Afi22Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}